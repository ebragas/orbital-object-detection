{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('../data/scenes/sfbay_1.png')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_width = image.size[0]\n",
    "orig_height = image.size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 80\n",
    "WIDTH = 80\n",
    "DEPTH = 3\n",
    "STEP = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = image.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy.crop((0, 0, 80, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy.crop((left, upper, right - 80, lower - 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a box\n",
    "toy = image.copy()\n",
    "draw = ImageDraw.Draw(toy)\n",
    "draw.rectangle((0, 0, 80, 80), outline='red', width=5)\n",
    "toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, upper, right, lower = toy.getbbox()\n",
    "left, upper, right, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num boxes by width\n",
    "STEP = 15\n",
    "w = (orig_width - (WIDTH - STEP)) // STEP\n",
    "h = (orig_height - (HEIGHT - STEP)) // STEP\n",
    "print('Total image chips:', h * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sizes = list(range(10, 51))\n",
    "\n",
    "num_boxes = []\n",
    "for step in step_sizes:\n",
    "    w = (orig_width - (WIDTH - step)) // step\n",
    "    h = (orig_height - (HEIGHT - step)) // step\n",
    "    num_boxes.append(w * h)\n",
    "    \n",
    "plt.plot(step_sizes, num_boxes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw bounding boxes over every potential image chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 80\n",
    "WIDTH = 80\n",
    "DEPTH = 3\n",
    "STEP = 10\n",
    "\n",
    "toy = image.copy()\n",
    "draw = ImageDraw.Draw(toy)\n",
    "\n",
    "for i in range((orig_height - (WIDTH - STEP)) // STEP):  # rows\n",
    "    upper = STEP * i\n",
    "    lower = upper + HEIGHT\n",
    "    \n",
    "    for j in range((orig_width - (WIDTH - STEP)) // STEP):\n",
    "        lefter = j * STEP\n",
    "        righter = lefter + WIDTH\n",
    "        \n",
    "        draw.rectangle((lefter, upper, righter, lower), outline='red', width=2)\n",
    "\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop image and convert to bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a couple points by trial and error\n",
    "x, y = 1680, 460\n",
    "\n",
    "toy = image.copy()\n",
    "draw = ImageDraw.Draw(toy)\n",
    "draw.line((0, y) + (toy.size[0], y), fill='red', width=5)\n",
    "draw.line((x, 0) + (x, toy.size[1]), fill='red', width=5)\n",
    "toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1640\n",
    "t = 430\n",
    "toy = image.copy()\n",
    "toy = toy.crop((l, t, l + WIDTH, t + HEIGHT))\n",
    "toy = toy.crop((l + 200, t + 200, l + WIDTH + 200, t + WIDTH + 200))\n",
    "clip1 = toy.copy()\n",
    "clip1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works!\n",
    "# toy.tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML prediction on an image chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import automl_v1beta1 as automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "PROJECT = 'reliable-realm-222318'\n",
    "REGION = 'us-central1'\n",
    "MODEL_ID = 'ICN5377742494555644521'\n",
    "IMG_PATH = '../data/imgs/ship/1__20160710_182140_0c78__-122.33185409502408_37.74917343586839.png'\n",
    "THRESHOLD = '0.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_client = automl.AutoMlClient()\n",
    "\n",
    "model_path = automl_client.model_path(PROJECT, REGION, MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_client = automl.PredictionServiceClient()\n",
    "\n",
    "with open(IMG_PATH, 'rb') as img_file:\n",
    "    content = img_file.read()\n",
    "    \n",
    "payload = {'image': {'image_bytes': content}}\n",
    "\n",
    "params = {}\n",
    "if THRESHOLD:\n",
    "    params = {'score_threshold': THRESHOLD}\n",
    "    \n",
    "response = prediction_client.predict(model_path, payload, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image from crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(clip1.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_bytes = io.BytesIO()\n",
    "clip1.save(image_bytes, format='PNG')\n",
    "\n",
    "payload = {'image': {'image_bytes': image_bytes.getvalue()}}\n",
    "\n",
    "params = {}\n",
    "if THRESHOLD:\n",
    "    params = {'score_threshold': THRESHOLD}\n",
    "    \n",
    "response = prediction_client.predict(model_path, payload, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAAAGGHGGGGHGGGHHHHHHHHHHH!!!!\n",
    "![Yes!](https://i.imgflip.com/wnv53.jpg)\n",
    "# YES!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop scene into clips, make predictions, save all prediction/coordinate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from google.cloud import automl_v1beta1 as automl\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Config\n",
    "HEIGHT = 80\n",
    "WIDTH = 80\n",
    "DEPTH = 3\n",
    "STEP = 25\n",
    "\n",
    "# AutoML Config\n",
    "PROJECT = 'reliable-realm-222318'\n",
    "REGION = 'us-central1'\n",
    "MODEL_ID = 'ICN5377742494555644521'\n",
    "THRESHOLD = '0.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image = Image.open('../../data/scenes/sfbay_1.png')\n",
    "toy = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yield sequence of 4 coord tuples\n",
    "# crop and predict on that clip\n",
    "# use cropping function in prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clip_bboxes(image, clip_height, clip_width, step_size):\n",
    "    '''Create generator of (left, top, right, bottom) 4 coord tuple for\n",
    "    every potential image clip in the provided image, of size\n",
    "    clip_height x clip_width\n",
    "    \n",
    "    image = PIL image\n",
    "    \n",
    "    Returns generator\n",
    "    '''\n",
    "    coords = []\n",
    "    \n",
    "    # Get original img size\n",
    "    img_height, img_width = image.size\n",
    "    \n",
    "    for i in range((img_height - (clip_height - step_size)) // step_size):\n",
    "        upper = step_size * i\n",
    "        lower = upper + clip_height\n",
    "        \n",
    "        for j in range((img_width - (clip_width - step_size)) // step_size):\n",
    "            left = j * step_size\n",
    "            right = left + clip_width\n",
    "            \n",
    "            yield (left, upper, right, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clips(bbox_gen, image):\n",
    "    '''doc'''\n",
    "\n",
    "    # Setup clients\n",
    "    automl_client = automl.AutoMlClient()\n",
    "    prediction_client = automl.PredictionServiceClient()\n",
    "    model_path = automl_client.model_path(PROJECT, REGION, MODEL_ID)\n",
    "\n",
    "    predictions = {}\n",
    "    ship_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    for coords in bbox_gen:\n",
    "        # crop clip\n",
    "        clip = image.copy()\n",
    "        clip = clip.crop(coords)\n",
    "        \n",
    "        # save to bytes\n",
    "        image_bytes = BytesIO()\n",
    "        clip.save(image_bytes, format='PNG')\n",
    "\n",
    "        payload = {'image': {'image_bytes': image_bytes.getvalue()}}\n",
    "        response = prediction_client.predict(model_path, payload)\n",
    "        \n",
    "        print(response)\n",
    "\n",
    "        predictions[coords] = response\n",
    "        \n",
    "        for pred in response.payload:\n",
    "            total_count += 1\n",
    "            if pred.display_name == 'ship' and pred.classification.score > 0.9:\n",
    "                ship_count += 1\n",
    "                print('Found a ship!')\n",
    "\n",
    "        \n",
    "        input() # ghetto debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = generate_clip_bboxes(toy, HEIGHT, WIDTH, STEP)\n",
    "predict_clips(bboxes, toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DONT RUN; REFERENCE ONLY\n",
    "\n",
    "# drawing\n",
    "for i in range((orig_height - (WIDTH - STEP)) // STEP):  # rows\n",
    "    upper = STEP * i\n",
    "    lower = upper + HEIGHT\n",
    "    \n",
    "    for j in range((orig_width - (WIDTH - STEP)) // STEP):\n",
    "        lefter = j * STEP\n",
    "        righter = lefter + WIDTH\n",
    "        \n",
    "        draw.rectangle((lefter, upper, righter, lower), outline='red', width=2)\n",
    "\n",
    "        \n",
    "# cropping\n",
    "l = 1640\n",
    "t = 430\n",
    "toy = image.copy()\n",
    "toy = toy.crop((l, t, l + WIDTH, t + HEIGHT))\n",
    "clip1 = toy.copy()\n",
    "clip1\n",
    "\n",
    "# predicting\n",
    "image_bytes = io.BytesIO()\n",
    "clip1.save(image_bytes, format='PNG')\n",
    "\n",
    "payload = {'image': {'image_bytes': image_bytes.getvalue()}}\n",
    "\n",
    "params = {}\n",
    "if THRESHOLD:\n",
    "    params = {'score_threshold': THRESHOLD}\n",
    "    \n",
    "response = prediction_client.predict(model_path, payload, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions with AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from google.cloud import automl_v1beta1 as automl\n",
    "from io import BytesIO\n",
    "\n",
    "# Image Config\n",
    "HEIGHT = 80\n",
    "WIDTH = 80\n",
    "DEPTH = 3\n",
    "STEP = 25\n",
    "\n",
    "# AutoML Config\n",
    "PROJECT = 'reliable-realm-222318'\n",
    "REGION = 'us-central1'\n",
    "MODEL_ID = 'ICN5377742494555644521'\n",
    "THRESHOLD = '0.5'\n",
    "\n",
    "# Load image\n",
    "image = Image.open('../../data/scenes/sfbay_1.png')\n",
    "toy = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clip_bboxes(image, clip_height, clip_width, step_size):\n",
    "    '''Create generator of (left, top, right, bottom) 4 coord tuple for\n",
    "    every potential image clip in the provided image, of size\n",
    "    clip_height x clip_width\n",
    "    \n",
    "    image = PIL image\n",
    "    \n",
    "    Returns generator\n",
    "    '''\n",
    "    coords = []\n",
    "    \n",
    "    # Get original img size\n",
    "    img_height, img_width = image.size\n",
    "    \n",
    "    for i in range((img_height - (clip_height - step_size)) // step_size):\n",
    "        upper = step_size * i\n",
    "        lower = upper + clip_height\n",
    "        \n",
    "        for j in range((img_width - (clip_width - step_size)) // step_size):\n",
    "            left = j * step_size\n",
    "            right = left + clip_width\n",
    "            \n",
    "            yield (left, upper, right, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clips(bbox_gen, image):\n",
    "    '''doc'''\n",
    "\n",
    "    # Setup clients\n",
    "    automl_client = automl.AutoMlClient()\n",
    "    prediction_client = automl.PredictionServiceClient()\n",
    "    model_path = automl_client.model_path(PROJECT, REGION, MODEL_ID)\n",
    "\n",
    "    predictions = {}\n",
    "    ship_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    for coords in bbox_gen:\n",
    "        # crop clip\n",
    "        clip = image.copy()\n",
    "        clip = clip.crop(coords)\n",
    "        \n",
    "        # save to bytes\n",
    "        image_bytes = BytesIO()\n",
    "        clip.save(image_bytes, format='PNG')\n",
    "\n",
    "        payload = {'image': {'image_bytes': image_bytes.getvalue()}}\n",
    "        response = prediction_client.predict(model_path, payload)\n",
    "        \n",
    "        print(response)\n",
    "\n",
    "        predictions[coords] = response\n",
    "        \n",
    "        for pred in response.payload:\n",
    "            total_count += 1\n",
    "            if pred.display_name == 'ship' and pred.classification.score > 0.9:\n",
    "                ship_count += 1\n",
    "                print('Found a ship!')\n",
    "\n",
    "        \n",
    "        input() # ghetto debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = generate_clip_bboxes(toy, HEIGHT, WIDTH, STEP)\n",
    "predict_clips(bboxes, toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions with ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the blob contents from storage\n",
    "# parse it as an image\n",
    "# b64 encode the image\n",
    "# make a prediction request\n",
    "# save the results\n",
    "\n",
    "# no. too much. Just run it local rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "import base64\n",
    "\n",
    "# Image Config\n",
    "HEIGHT, WIDTH, DEPTH, STEP = 80, 80, 3, 25\n",
    "\n",
    "# Model Config\n",
    "PROJECT = 'reliable-realm-222318'\n",
    "REGION = 'us-central1'\n",
    "MODEL = 'satellite'\n",
    "PROJECT_ID = 'projects/{}'.format(PROJECT)\n",
    "MODEL_ID = PROJECT_ID + '/models/{}'.format(MODEL)\n",
    "\n",
    "# Load image\n",
    "image = Image.open('../../data/scenes/sfbay_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cmle(bbox_gen, image):\n",
    "    '''doc'''\n",
    "\n",
    "    # Setup clients\n",
    "    ml = discovery.build('ml', 'v1', cache_discovery=False)\n",
    "    \n",
    "    predictions = {}\n",
    "    ship_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    for coords in bbox_gen:\n",
    "        # crop clip\n",
    "        clip = image.copy()\n",
    "        clip = clip.crop(coords)\n",
    "        \n",
    "        # save to bytes\n",
    "        image_bytes = BytesIO()\n",
    "        clip.save(image_bytes, format='PNG')\n",
    "\n",
    "        body = {'instances': {'image_bytes': {'b64': base64.b64encode(image_bytes.getvalue()).decode()}}}\n",
    "        request = ml.projects().predict(name=MODEL_ID, body=body)\n",
    "        response = request.execute()\n",
    "        \n",
    "#         print(coords, response)\n",
    "\n",
    "        predictions[coords] = response\n",
    "\n",
    "        for pred in response['predictions']:\n",
    "            if pred['probabilities'][1] > 0.5:\n",
    "                print('Found a ship at: {}!'.format(coords))\n",
    "                print(response)\n",
    "                ship_count += 1\n",
    "        \n",
    "#         input()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = generate_clip_bboxes(image, HEIGHT, WIDTH, STEP)\n",
    "predictions = predict_cmle(bboxes, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coords, pred in predictions.items():\n",
    "    if pred['predictions'][0]['class'] == 'ship':\n",
    "        print(coords, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of pos. probs\n",
    "pos_probs = np.array([pred['predictions'][0]['probabilities'][1] for pred in predictions.values()])\n",
    "neg_probs = np.array([pred['predictions'][0]['probabilities'][0] for pred in predictions.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pos_probs, density=True, bins=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(pos_probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctile = np.percentile(pos_probs, 99)\n",
    "pctile, pos_probs[pos_probs > pctile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_probs[pos_probs > 0.2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
